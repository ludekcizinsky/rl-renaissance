{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import wandb\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download locally the best models from wandb\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = \"/scratch/izar/cizinsky/rl-for-kinetics/best_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {CKPT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get overview of the relevant runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kvxbygvv | zesty-bird-206 | tags: ['baseline', 'part2']\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "runs = api.runs(\"ludekcizinsky/rl-renaissance\")\n",
    "\n",
    "tagged_runs = [run for run in runs if \"part2\" in run.tags]\n",
    "\n",
    "for run in tagged_runs:\n",
    "    print(f\"{run.id} | {run.name} | tags: {run.tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the best model for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading checkpoint for run kvxbygvv...\n",
      "ludekcizinsky/rl-renaissance/zesty-bird-206:v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded checkpoint to /scratch/izar/cizinsky/rl-for-kinetics/best_models/zesty-bird-206.\n"
     ]
    }
   ],
   "source": [
    "run_ids = [run.id for run in tagged_runs]\n",
    "\n",
    "for run_id in run_ids:\n",
    "    print(f\"Downloading checkpoint for run {run_id}...\")\n",
    "    run = next((run for run in runs if run.id == run_id), None)\n",
    "    assert run is not None, \"Run not found!\"\n",
    "\n",
    "    artifact_path = f\"ludekcizinsky/rl-renaissance/{run.name}:v0\"\n",
    "    print(artifact_path)\n",
    "    artifact = api.artifact(artifact_path, type=\"model\")\n",
    "    os.makedirs(f\"{CKPT_DIR}/{run.name}\", exist_ok=True)\n",
    "    download_path = f\"{CKPT_DIR}/{run.name}\"\n",
    "\n",
    "    # Config\n",
    "    run_cfg = OmegaConf.create(run.config)\n",
    "    OmegaConf.save(run_cfg, f\"{download_path}/config.yaml\")\n",
    "\n",
    "    # Checkpoints\n",
    "    artifact.download(download_path)\n",
    "    print(f\"Downloaded checkpoint to {download_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "apptainer shell --nv --bind \"$(pwd)\":/home/renaissance/work --bind \"/scratch/izar/$USER/rl-for-kinetics/output:/home/renaissance/output\" --bind \"/scratch/izar/$USER/rl-for-kinetics/best_models:/home/renaissance/best_models\" /scratch/izar/$USER/images/renaissance_with_ml.sif\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celestial-dragon-134  fragrant-plasma-133  sandy-blaze-130     vibrant-oath-142\n",
      "chocolate-sponge-135  hearty-pine-137\t   stilted-lake-138    zesty-bird-206\n",
      "comfy-terrain-128     olive-forest-140\t   sweet-eon-143\n",
      "crisp-sunset-141      resilient-oath-127   upbeat-thunder-139\n"
     ]
    }
   ],
   "source": [
    "!ls /home/renaissance/best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_setup_e11_s3.pt  config.yaml  policy.pt  value.pt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/renaissance/best_models/zesty-bird-206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from helpers.utils import setup_kinetic_env, get_incidence_rate\n",
    "from helpers.ppo_agent import PolicyNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = \"zesty-bird-206\"\n",
    "ckpt_dir = f\"/home/renaissance/best_models/{selected_model}\"\n",
    "best_setup_path = f\"{ckpt_dir}/policy.pt\"\n",
    "config_path = f\"{ckpt_dir}/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/renaissance/best_models/zesty-bird-206/best_setup_e11_s3.pt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_setup_filename = [f for f in os.listdir(ckpt_dir) if \"best_setup\" in f][0]\n",
    "best_setup_path = f\"{ckpt_dir}/{best_setup_filename}\"\n",
    "best_setup_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best setup: episode 11, step 3\n"
     ]
    }
   ],
   "source": [
    "episode_str = best_setup_filename.split(\"_\")[2]\n",
    "episode = int(episode_str.split(\"e\")[1])\n",
    "step_str = best_setup_filename.split(\"_\")[3].strip(\".pt\")\n",
    "step = int(step_str.split(\"s\")[1])\n",
    "print(f\"Best setup: episode {episode}, step {step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "env:\n",
      "  p_size: 384\n",
      "  action_scale: 1\n",
      "seed: 42\n",
      "paths:\n",
      "  names_km: data/varma_ecoli_shikki/parameter_names_km_fdp1.pkl\n",
      "  output_dir: /home/renaissance/output\n",
      "  met_model_name: varma_ecoli_shikki\n",
      "device: cpu\n",
      "logger:\n",
      "  tags:\n",
      "  - baseline\n",
      "  entity: ludekcizinsky\n",
      "  project: rl-renaissance\n",
      "method:\n",
      "  name: ppo_refinement\n",
      "  actor_lr: 0.0003\n",
      "  clip_eps: 0.2\n",
      "  critic_lr: 0.001\n",
      "  gae_lambda: 0.98\n",
      "  parameter_dim: 384\n",
      "  discount_factor: 0.99\n",
      "  value_loss_weight: 0.5\n",
      "reward:\n",
      "  eig_partition: -2.5\n",
      "training:\n",
      "  batch_size: 25\n",
      "  num_epochs: 10\n",
      "  num_episodes: 100\n",
      "  max_grad_norm: 0.5\n",
      "  save_trained_models: true\n",
      "  max_steps_per_episode: 50\n",
      "  n_eval_samples_in_episode: 50\n",
      "launch_cmd: train.py\n",
      "constraints:\n",
      "  max_km: 3\n",
      "  min_km: -25\n",
      "  ss_idx: 1712\n",
      "lr_scheduler:\n",
      "  name: constant\n",
      "\n",
      "--------------------------------------------------\n",
      "FYI: Loading kinetic and thermodynamic data.\n"
     ]
    }
   ],
   "source": [
    "kinetic_env = setup_kinetic_env(cfg)\n",
    "kinetic_env.logging_enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup = torch.load(best_setup_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps_per_episode = 10 # cfg.training.max_steps_per_episode\n",
    "num_samples = 50\n",
    "for i in range(10):\n",
    "    incidence_rate, all_max_eigs = get_incidence_rate(kinetic_env, best_setup, num_samples, device)\n",
    "    print(f\"[Eval {i}] Incidence rate: {incidence_rate}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaexam22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
