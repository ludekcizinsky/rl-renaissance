{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download locally the best models from wandb\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = \"/scratch/izar/cizinsky/rl-for-kinetics/best_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {CKPT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get overview of the relevant runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "runs = api.runs(\"ludekcizinsky/rl-renaissance\")\n",
    "\n",
    "tagged_runs = [run for run in runs if \"part1\" in run.tags]\n",
    "\n",
    "for run in tagged_runs:\n",
    "    print(f\"{run.id} | {run.name} | tags: {run.tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the best model for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [run.id for run in tagged_runs]\n",
    "\n",
    "for run_id in run_ids:\n",
    "    print(f\"Downloading checkpoint for run {run_id}...\")\n",
    "    run = next((run for run in runs if run.id == run_id), None)\n",
    "    assert run is not None, \"Run not found!\"\n",
    "\n",
    "    artifact_path = f\"ludekcizinsky/rl-renaissance/{run.name}:v0\"\n",
    "    print(artifact_path)\n",
    "    artifact = api.artifact(artifact_path, type=\"model\")\n",
    "    os.makedirs(f\"{CKPT_DIR}/{run.name}\", exist_ok=True)\n",
    "    download_path = f\"{CKPT_DIR}/{run.name}\"\n",
    "\n",
    "    # Config\n",
    "    run_cfg = OmegaConf.create(run.config)\n",
    "    OmegaConf.save(run_cfg, f\"{download_path}/config.yaml\")\n",
    "\n",
    "    # Checkpoints\n",
    "    if os.path.exists(download_path):\n",
    "        print(f\"Checkpoint for run {run.name} already exists in {download_path}.\")\n",
    "        continue\n",
    "    artifact.download(download_path)\n",
    "    print(f\"Downloaded checkpoint to {download_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "apptainer shell --nv --bind \"$(pwd)\":/home/renaissance/work --bind \"/scratch/izar/$USER/rl-for-kinetics/output:/home/renaissance/output\" --bind \"/scratch/izar/$USER/rl-for-kinetics/best_models:/home/renaissance/best_models\" /scratch/izar/$USER/images/renaissance_with_ml.sif\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celestial-dragon-134  fragrant-plasma-133  sandy-blaze-130     vibrant-oath-142\n",
      "chocolate-sponge-135  hearty-pine-137\t   stilted-lake-138\n",
      "comfy-terrain-128     olive-forest-140\t   sweet-eon-143\n",
      "crisp-sunset-141      resilient-oath-127   upbeat-thunder-139\n"
     ]
    }
   ],
   "source": [
    "!ls /home/renaissance/best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.yaml  policy.pt\tvalue.pt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/renaissance/best_models/resilient-oath-127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-jo7x88oq because the default path (/scratch/izar/cizinsky/.cache/hf/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from helpers.utils import setup_kinetic_env, get_incidence_rate\n",
    "from helpers.ppo_agent import PolicyNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = \"resilient-oath-127\"\n",
    "model_path = f\"/home/renaissance/best_models/{selected_model}/policy.pt\"\n",
    "config_path = f\"/home/renaissance/best_models/{selected_model}/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "env:\n",
      "  p_size: 384\n",
      "  action_scale: 1\n",
      "seed: 42\n",
      "paths:\n",
      "  names_km: data/varma_ecoli_shikki/parameter_names_km_fdp1.pkl\n",
      "  output_dir: /home/renaissance/output\n",
      "  met_model_name: varma_ecoli_shikki\n",
      "device: cpu\n",
      "logger:\n",
      "  tags:\n",
      "  - baseline\n",
      "  entity: ludekcizinsky\n",
      "  project: rl-renaissance\n",
      "method:\n",
      "  name: ppo_refinement\n",
      "  actor_lr: 0.0003\n",
      "  clip_eps: 0.2\n",
      "  critic_lr: 0.001\n",
      "  gae_lambda: 0.98\n",
      "  parameter_dim: 384\n",
      "  discount_factor: 0.99\n",
      "  value_loss_weight: 0.5\n",
      "reward:\n",
      "  eig_partition: -2.5\n",
      "training:\n",
      "  batch_size: 25\n",
      "  num_epochs: 10\n",
      "  num_episodes: 100\n",
      "  max_grad_norm: 0.5\n",
      "  save_trained_models: true\n",
      "  max_steps_per_episode: 50\n",
      "  n_eval_samples_in_episode: 50\n",
      "launch_cmd: train.py\n",
      "constraints:\n",
      "  max_km: 3\n",
      "  min_km: -25\n",
      "  ss_idx: 1712\n",
      "lr_scheduler:\n",
      "  name: constant\n",
      "\n",
      "--------------------------------------------------\n",
      "FYI: Loading kinetic and thermodynamic data.\n"
     ]
    }
   ],
   "source": [
    "kinetic_env = setup_kinetic_env(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinetic_env.logging_enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FYI: Loaded pretrained policy network from /home/renaissance/best_models/resilient-oath-127/policy.pt.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PolicyNetwork(\n",
       "  (base): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "    (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "    (4): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (mean_head): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=384, bias=True)\n",
       "    (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (log_std_head): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=384, bias=True)\n",
       "    (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net = PolicyNetwork(cfg)\n",
    "policy_net.load_pretrained_policy_net(model_path)\n",
    "policy_net.eval()\n",
    "policy_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting best setup:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting best setup: 100%|██████████| 30/30 [00:08<00:00,  3.50it/s]\n",
      "Evaluating best setup: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval 0] Incidence rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting best setup: 100%|██████████| 30/30 [00:08<00:00,  3.51it/s]\n",
      "Evaluating best setup: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval 1] Incidence rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting best setup: 100%|██████████| 30/30 [00:08<00:00,  3.53it/s]\n",
      "Evaluating best setup: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval 2] Incidence rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting best setup: 100%|██████████| 30/30 [00:08<00:00,  3.54it/s]\n",
      "Evaluating best setup: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval 3] Incidence rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting best setup: 100%|██████████| 30/30 [00:08<00:00,  3.52it/s]\n",
      "Evaluating best setup: 100%|██████████| 100/100 [00:28<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval 4] Incidence rate: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting best setup: 100%|██████████| 30/30 [00:08<00:00,  3.48it/s]\n",
      "Evaluating best setup: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval 5] Incidence rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting best setup: 100%|██████████| 30/30 [00:08<00:00,  3.50it/s]\n",
      "Evaluating best setup: 100%|██████████| 100/100 [00:28<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval 6] Incidence rate: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting best setup: 100%|██████████| 30/30 [00:08<00:00,  3.50it/s]\n",
      "Evaluating best setup: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval 7] Incidence rate: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting best setup: 100%|██████████| 30/30 [00:08<00:00,  3.49it/s]\n",
      "Evaluating best setup: 100%|██████████| 100/100 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval 8] Incidence rate: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting best setup: 100%|██████████| 30/30 [00:08<00:00,  3.50it/s]\n",
      "Evaluating best setup: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval 9] Incidence rate: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_steps_per_episode = 10 # cfg.training.max_steps_per_episode\n",
    "num_samples = 50\n",
    "for i in range(10):\n",
    "    incidence_rate, all_max_eigs = get_incidence_rate(kinetic_env, policy_net, max_steps_per_episode, num_samples, device)\n",
    "    print(f\"[Eval {i}] Incidence rate: {incidence_rate}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaexam22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
