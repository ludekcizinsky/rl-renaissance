{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show how to use our best model (or any other model saved during training) to generate kinetic models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you have downloaded the best models, and you are at the root of the repository, then start the container with the following command (make sure to replace the output and inference models paths with your own):\n",
    "\n",
    "```bash\n",
    "apptainer shell --nv --bind \"$(pwd)\":/home/renaissance/work --bind \"/scratch/izar/$USER/rl-for-kinetics/output:/home/renaissance/output\" --bind \"/home/$USER/rl-gen-of-kinetic-models/inference:/home/renaissance/inference\" /scratch/izar/$USER/images/renaissance_with_ml.sif\n",
    "```\n",
    "\n",
    "\n",
    "Then, start the Jupyter notebook with the following command:\n",
    "\n",
    "```bash\n",
    "jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below commands make sure you are in the right directory and have all the necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..') # important: run this cell only once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch\n",
    "\n",
    "from helpers.utils import setup_kinetic_env, sample_params\n",
    "from helpers.ppo_agent import PolicyNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate kinetic parameters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define name of the model you want to use for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = \"best_model\" # name of the folder in your best_models directory \n",
    "ckpt_dir = f\"/home/renaissance/inference/{selected_model}\"\n",
    "policy_path = f\"{ckpt_dir}/policy.pt\"\n",
    "config_path = f\"{ckpt_dir}/config.yaml\"\n",
    "normalisation_path = f\"{ckpt_dir}/normalisation.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the kinetic RL environment (which includes the reward function) Take around 30 seconds. In addition, it prints the configuration of the environment and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "env:\n",
      "  p_size: 384\n",
      "  action_scale: 1\n",
      "seed: 42\n",
      "paths:\n",
      "  names_km: data/varma_ecoli_shikki/parameter_names_km_fdp1.pkl\n",
      "  output_dir: /home/renaissance/output\n",
      "  met_model_name: varma_ecoli_shikki\n",
      "device: cpu\n",
      "logger:\n",
      "  tags:\n",
      "  - debug\n",
      "  - best_setup\n",
      "  - clip_eps_decay\n",
      "  - reproduce\n",
      "  entity: ludekcizinsky\n",
      "  project: rl-renaissance\n",
      "method:\n",
      "  name: ppo_refinement\n",
      "  actor_lr: 0.0001\n",
      "  critic_lr: 0.001\n",
      "  gae_lambda: 0.98\n",
      "  max_log_std: 2\n",
      "  min_log_std: -6\n",
      "  clip_eps_end: 0.1\n",
      "  parameter_dim: 384\n",
      "  clip_eps_start: 0.3\n",
      "  discount_factor: 0.99\n",
      "  value_loss_weight: 0.5\n",
      "  entropy_loss_weight: 0.01\n",
      "reward:\n",
      "  eig_partition: -2.5\n",
      "training:\n",
      "  batch_size: 25\n",
      "  num_epochs: 10\n",
      "  num_episodes: 100\n",
      "  max_grad_norm: 0.5\n",
      "  save_trained_models: true\n",
      "  max_steps_per_episode: 50\n",
      "  n_eval_samples_in_episode: 50\n",
      "launch_cmd: train.py logger.tags=[debug, best_setup, clip_eps_decay, reproduce]\n",
      "constraints:\n",
      "  max_km: 3\n",
      "  min_km: -25\n",
      "  ss_idx: 1712\n",
      "lr_scheduler:\n",
      "  name: constant\n",
      "\n",
      "--------------------------------------------------\n",
      "FYI: Loading kinetic and thermodynamic data.\n"
     ]
    }
   ],
   "source": [
    "kinetic_env = setup_kinetic_env(cfg)\n",
    "kinetic_env.logging_enabled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the policy network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FYI: Loaded pretrained policy network from /home/renaissance/inference/best_model/policy.pt.\n"
     ]
    }
   ],
   "source": [
    "policy = PolicyNetwork(cfg)\n",
    "policy.load_pretrained_policy_net(policy_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load normalisation parameters to scale the states during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalisation = torch.load(normalisation_path)\n",
    "obs_mean, obs_var = normalisation[\"obs_mean\"], normalisation[\"obs_var\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, sample the kinetic parameters ($N$ is the number of samples, $\\text{max\\_steps}$ is the maximum number of env steps for each sample).\n",
    "\n",
    "If deterministic is set to `True`, the policy will always take the mean as the action. If verbose is set to `True`, it will print the max eigenvalue and reward for each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling parameters:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: max_eig: 1286.6741302019732, reward: 0.0010000020611536182\n",
      "[1]: max_eig: 95.74345568879855, reward: 0.0010000020611536182\n",
      "[2]: max_eig: 0.3227273018170841, reward: 0.05710832020412048\n",
      "[3]: max_eig: 561.2529998133442, reward: 0.0010000020611536182\n",
      "[4]: max_eig: 0.5135783828163806, reward: 0.04781620312404489\n",
      "[5]: max_eig: 2.372957367329585, reward: 0.00859261697165222\n",
      "[6]: max_eig: 1.29042514316338, reward: 0.023087137494391622\n",
      "[7]: max_eig: -0.42674525248723333, reward: 0.11272362424820181\n",
      "[8]: max_eig: -1.7536339531521101, reward: 0.32261363606294313\n",
      "[9]: max_eig: -1.5562585935990072, reward: 0.28114521581425106\n",
      "[10]: max_eig: -0.7931721452601949, reward: 0.15457561039892273\n",
      "[11]: max_eig: -0.6250504368538443, reward: 0.13397005490560865\n",
      "[12]: max_eig: -1.0680156674880774, reward: 0.1937896905213515\n",
      "[13]: max_eig: -1.4083786183658895, reward: 0.25231308463418906\n",
      "[14]: max_eig: -0.9241762924918994, reward: 0.17238776031509637\n",
      "[15]: max_eig: -1.9759917778139229, reward: 0.3729154559529184\n",
      "[16]: max_eig: -2.236427560079094, reward: 0.4354857270033993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling parameters:  10%|█         | 1/10 [00:05<00:46,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]: max_eig: -2.5764463436210723, reward: 0.5201022839298046\n",
      "[0]: max_eig: 104.73993219560546, reward: 0.0010000020611536182\n",
      "[1]: max_eig: 8.28913805436602, reward: 0.0010206218641927334\n",
      "[2]: max_eig: -0.05698509111369617, reward: 0.0809508582955542\n",
      "[3]: max_eig: -0.05698548808375075, reward: 0.08095088749616759\n",
      "[4]: max_eig: -0.0569063881561251, reward: 0.08094506919823431\n",
      "[5]: max_eig: -0.10988675134866159, reward: 0.08492972430517984\n",
      "[6]: max_eig: 0.08022402805200408, reward: 0.07142206397850658\n",
      "[7]: max_eig: 0.22850302643608403, reward: 0.062312261684060004\n",
      "[8]: max_eig: -0.8859654609680433, reward: 0.16702922412334503\n",
      "[9]: max_eig: -1.4795104594287287, reward: 0.26593205493403005\n",
      "[10]: max_eig: -1.1724119606509529, reward: 0.21055861166164774\n",
      "[11]: max_eig: -1.4429061913577446, reward: 0.2588652232368188\n",
      "[12]: max_eig: -1.3066617382995593, reward: 0.2336624220419001\n",
      "[13]: max_eig: -1.7776791895921327, reward: 0.3278821295290538\n",
      "[14]: max_eig: -1.0318572182998917, reward: 0.18822506614020784\n",
      "[15]: max_eig: -1.608121927086271, reward: 0.29172241121423165\n",
      "[16]: max_eig: -1.2926555388214107, reward: 0.23117125518238185\n",
      "[17]: max_eig: -1.2267509089892872, reward: 0.21970156864634066\n",
      "[18]: max_eig: -1.2986185608519782, reward: 0.2322295573229562\n",
      "[19]: max_eig: -1.3338687542212215, reward: 0.23855499154915763\n",
      "[20]: max_eig: -0.5279574674464566, reward: 0.12316966786962512\n",
      "[21]: max_eig: -1.0254559457493717, reward: 0.18725292241756838\n",
      "[22]: max_eig: -0.7746121453333098, reward: 0.15217847488994254\n",
      "[23]: max_eig: -1.5256813291060234, reward: 0.27502053690409617\n",
      "[24]: max_eig: -1.6267245272580124, reward: 0.2955732016382936\n",
      "[25]: max_eig: -1.5719662437251967, reward: 0.28432379293879495\n",
      "[26]: max_eig: -1.640418240082257, reward: 0.29842673540082165\n",
      "[27]: max_eig: -1.5761736904656176, reward: 0.2851788992787613\n",
      "[28]: max_eig: -1.5902820415399141, reward: 0.28805755513753134\n",
      "[29]: max_eig: -1.7026814512883326, reward: 0.3115993992987385\n",
      "[30]: max_eig: -1.6480563607056145, reward: 0.3000252938364697\n",
      "[31]: max_eig: -2.0309437231488, reward: 0.3858396345301719\n",
      "[32]: max_eig: -1.9582236805257536, reward: 0.36877446191899105\n",
      "[33]: max_eig: -1.3693260538083927, reward: 0.24503674796870023\n",
      "[34]: max_eig: -0.6012002913126612, reward: 0.13124438396945642\n",
      "[35]: max_eig: -0.7311008872640423, reward: 0.1466792884424983\n",
      "[36]: max_eig: -0.8933305337046611, reward: 0.16805152798496403\n",
      "[37]: max_eig: -0.7822810279732844, reward: 0.15316520783096457\n",
      "[38]: max_eig: -1.0889434604962445, reward: 0.1970674658314854\n",
      "[39]: max_eig: -1.163667954400029, reward: 0.20911389946635955\n",
      "[40]: max_eig: -1.1783334367027931, reward: 0.21154115440315446\n",
      "[41]: max_eig: -1.256332632689847, reward: 0.2247982725531246\n",
      "[42]: max_eig: -0.8125106920185691, reward: 0.15710630597608874\n",
      "[43]: max_eig: -0.9867881936388081, reward: 0.18146329130730585\n",
      "[44]: max_eig: -1.153992952785817, reward: 0.20752393742393027\n",
      "[45]: max_eig: -1.1856849838618708, reward: 0.2127656815933597\n",
      "[46]: max_eig: -0.30780463868314384, reward: 0.10145354086779089\n",
      "[47]: max_eig: -1.1034599647676562, reward: 0.1993657296985607\n",
      "[48]: max_eig: -0.04586908448658397, reward: 0.08013698765414154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling parameters:  20%|██        | 2/10 [00:19<01:23, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49]: max_eig: -0.1117540422157276, reward: 0.08507340353122111\n",
      "[0]: max_eig: 24.902780603217614, reward: 0.0010000020611536182\n",
      "[1]: max_eig: 25.96396093989543, reward: 0.0010000020611536182\n",
      "[2]: max_eig: -0.017174473020853943, reward: 0.07807097912765915\n",
      "[3]: max_eig: 108.87859708447749, reward: 0.0010000020611536182\n",
      "[4]: max_eig: 104.46909302798099, reward: 0.0010000020611536182\n",
      "[5]: max_eig: 37.22655953315994, reward: 0.0010000020611536182\n",
      "[6]: max_eig: -0.3859783926754971, reward: 0.10874144634968114\n",
      "[7]: max_eig: -0.39001243148503506, reward: 0.1091298656212032\n",
      "[8]: max_eig: -0.3983020562967804, reward: 0.10993189956193132\n",
      "[9]: max_eig: -0.385907674934719, reward: 0.10873464821362845\n",
      "[10]: max_eig: -0.3941464632476948, reward: 0.10952918887674926\n",
      "[11]: max_eig: -0.40403166272744734, reward: 0.11048929546808745\n",
      "[12]: max_eig: -0.4084289666179176, reward: 0.11091877551672447\n",
      "[13]: max_eig: -0.4048231615432571, reward: 0.11056649155894595\n",
      "[14]: max_eig: -0.4034233572178502, reward: 0.11042999892328399\n",
      "[15]: max_eig: -0.4009928768427574, reward: 0.11019336102823303\n",
      "[16]: max_eig: -0.4139295697168105, reward: 0.11145809187414578\n",
      "[17]: max_eig: -0.4737907213320365, reward: 0.1174784630763322\n",
      "[18]: max_eig: -0.4059573759473223, reward: 0.11067719642872464\n",
      "[19]: max_eig: -0.42161445784312274, reward: 0.11221545019916235\n",
      "[20]: max_eig: -0.4045978253936501, reward: 0.11054450932070625\n",
      "[21]: max_eig: -0.4213951422990796, reward: 0.11219377345743135\n",
      "[22]: max_eig: -0.4632702013546704, reward: 0.11640014421402722\n",
      "[23]: max_eig: -0.3995063258892413, reward: 0.11004884794494371\n",
      "[24]: max_eig: -0.39870981411844497, reward: 0.10997148518878447\n",
      "[25]: max_eig: -0.574324666366579, reward: 0.1282300284273827\n",
      "[26]: max_eig: -0.3056175893719851, reward: 0.10125608596695568\n",
      "[27]: max_eig: -0.5678859523534073, reward: 0.12751677160969122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling parameters:  30%|███       | 3/10 [00:27<01:06,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28]: max_eig: -2.6132289326601015, reward: 0.5292770284621189\n",
      "[0]: max_eig: -0.41309100271096183, reward: 0.11137572362146687\n",
      "[1]: max_eig: -0.8213407714253336, reward: 0.1582730907577058\n",
      "[2]: max_eig: -0.932514016754161, reward: 0.17357508008785194\n",
      "[3]: max_eig: -1.0188422863185642, reward: 0.18625261716162525\n",
      "[4]: max_eig: 2341.4636756445, reward: 0.0010000020611536182\n",
      "[5]: max_eig: 5262.883266092898, reward: 0.0010000020611536182\n",
      "[6]: max_eig: 1671.7976180900112, reward: 0.0010000020611536182\n",
      "[7]: max_eig: 140.44379076104028, reward: 0.0010000020611536182\n",
      "[8]: max_eig: 2052.197019832958, reward: 0.0010000020611536182\n",
      "[9]: max_eig: 4163.999596455726, reward: 0.0010000020611536182\n",
      "[10]: max_eig: 3578.693311262437, reward: 0.0010000020611536182\n",
      "[11]: max_eig: 4070.712393954, reward: 0.0010000020611536182\n",
      "[12]: max_eig: 4494.473208419784, reward: 0.0010000020611536182\n",
      "[13]: max_eig: 4228.227864401281, reward: 0.0010000020611536182\n",
      "[14]: max_eig: 3305.1483019497837, reward: 0.0010000020611536182\n",
      "[15]: max_eig: 2759.22771170128, reward: 0.0010000020611536182\n",
      "[16]: max_eig: 2643.317010134657, reward: 0.0010000020611536182\n",
      "[17]: max_eig: 2841.2379329982527, reward: 0.0010000020611536182\n",
      "[18]: max_eig: 2513.90362896632, reward: 0.0010000020611536182\n",
      "[19]: max_eig: 1729.702000364598, reward: 0.0010000020611536182\n",
      "[20]: max_eig: -0.6849793917879664, reward: 0.14103243389940412\n",
      "[21]: max_eig: -0.10033555073115223, reward: 0.08419828749369695\n",
      "[22]: max_eig: -0.09249627901323638, reward: 0.08360228703512161\n",
      "[23]: max_eig: 99.58584173379606, reward: 0.0010000020611536182\n",
      "[24]: max_eig: -0.04802599608008514, reward: 0.08029431388439902\n",
      "[25]: max_eig: 3.8110786479361067, reward: 0.002812781135272946\n",
      "[26]: max_eig: 109.62114227439467, reward: 0.0010000020611536182\n",
      "[27]: max_eig: 92.1250768640854, reward: 0.0010000020611536182\n",
      "[28]: max_eig: 46.0235686914933, reward: 0.0010000020611536182\n",
      "[29]: max_eig: -0.06347659250165938, reward: 0.0814296687338997\n",
      "[30]: max_eig: -0.11352473651054029, reward: 0.08520985642189437\n",
      "[31]: max_eig: 5.7357932214044105, reward: 0.0012649264856807987\n",
      "[32]: max_eig: 455.6028961456561, reward: 0.0010000020611536182\n",
      "[33]: max_eig: 238.84035994743326, reward: 0.0010000020611536182\n",
      "[34]: max_eig: 2.4955060437123104, reward: 0.007722793329309893\n",
      "[35]: max_eig: 0.041362538777265284, reward: 0.07400890503219269\n",
      "[36]: max_eig: -0.4039779624503761, reward: 0.11048405972624617\n",
      "[37]: max_eig: -0.059416523965097195, reward: 0.08112989414527244\n",
      "[38]: max_eig: -0.037501361444511425, reward: 0.07952933896776161\n",
      "[39]: max_eig: -0.010573617035808279, reward: 0.07760276217306704\n",
      "[40]: max_eig: -0.0038145154198004714, reward: 0.07712602474899984\n",
      "[41]: max_eig: -0.0016270004860358216, reward: 0.07697231754085665\n",
      "[42]: max_eig: -0.0013122994235880237, reward: 0.07695022830902225\n",
      "[43]: max_eig: -0.0006296655740385969, reward: 0.07690233370872038\n",
      "[44]: max_eig: -0.0018965584768621871, reward: 0.07699124281624341\n",
      "[45]: max_eig: -0.002012958767966586, reward: 0.07699941644927606\n",
      "[46]: max_eig: -0.006394864104384007, reward: 0.07730770148008152\n",
      "[47]: max_eig: -0.00403486248659007, reward: 0.07714152339368752\n",
      "[48]: max_eig: -0.002979101170813621, reward: 0.07706729015411705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling parameters:  40%|████      | 4/10 [00:42<01:09, 11.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49]: max_eig: -0.00198311135686942, reward: 0.07699732048597448\n",
      "[0]: max_eig: 1165.766198790649, reward: 0.0010000020611536182\n",
      "[1]: max_eig: 4418.858207949433, reward: 0.0010000020611536182\n",
      "[2]: max_eig: -0.29607683645054106, reward: 0.10039874052444255\n",
      "[3]: max_eig: 3661.1165813433554, reward: 0.0010000020611536182\n",
      "[4]: max_eig: 3733.9048949983817, reward: 0.0010000020611536182\n",
      "[5]: max_eig: 7099.644083833706, reward: 0.0010000020611536182\n",
      "[6]: max_eig: 63.27742456877301, reward: 0.0010000020611536182\n",
      "[7]: max_eig: 460.66865745377385, reward: 0.0010000020611536182\n",
      "[8]: max_eig: 292.3579618427961, reward: 0.0010000020611536182\n",
      "[9]: max_eig: 174.2998669967932, reward: 0.0010000020611536182\n",
      "[10]: max_eig: 70.58529930352222, reward: 0.0010000020611536182\n",
      "[11]: max_eig: 172.63598721773135, reward: 0.0010000020611536182\n",
      "[12]: max_eig: 27.0341051906261, reward: 0.0010000020611536182\n",
      "[13]: max_eig: 4.821955566645194, reward: 0.001660432115356872\n",
      "[14]: max_eig: 1.1971769646869344, reward: 0.025193578894642587\n",
      "[15]: max_eig: 0.013142887597650237, reward: 0.0759419355011473\n",
      "[16]: max_eig: -1.1144625488042381, reward: 0.20112113308812837\n",
      "[17]: max_eig: -0.5691514390386617, reward: 0.1276566870058927\n",
      "[18]: max_eig: -0.04198004626557989, reward: 0.07985404009122081\n",
      "[19]: max_eig: -0.17554988481066228, reward: 0.09011815516106916\n",
      "[20]: max_eig: 1.9115967719908584, reward: 0.012990273392070657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling parameters:  50%|█████     | 5/10 [00:48<00:48,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]: max_eig: -3.327595675591532, reward: 0.6968463081949866\n",
      "[0]: max_eig: 48.030829126980116, reward: 0.0010000020611536182\n",
      "[1]: max_eig: 22.090590182716305, reward: 0.0010000020611536182\n",
      "[2]: max_eig: 13.914698608071348, reward: 0.0010000743339036021\n",
      "[3]: max_eig: 0.4274019483434705, reward: 0.05181549133674975\n",
      "[4]: max_eig: -0.2432744532600435, reward: 0.09577090977837838\n",
      "[5]: max_eig: -0.18996054100142684, reward: 0.09129490341996166\n",
      "[6]: max_eig: -2.2855782392808384, reward: 0.4475990033068087\n",
      "[7]: max_eig: -2.351575128538629, reward: 0.4639617530527744\n",
      "[8]: max_eig: -1.368430962369769, reward: 0.24487165681680642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling parameters:  60%|██████    | 6/10 [00:51<00:29,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]: max_eig: -2.648794375067219, reward: 0.5381301146935885\n",
      "[0]: max_eig: -0.00255258190821155, reward: 0.07703731934892703\n",
      "[1]: max_eig: -0.0026282355726220718, reward: 0.07704263461642931\n",
      "[2]: max_eig: -0.002516992589601611, reward: 0.07703481903610455\n",
      "[3]: max_eig: -0.022618194727796668, reward: 0.07845908932285446\n",
      "[4]: max_eig: -0.002509652369798259, reward: 0.07703430336139143\n",
      "[5]: max_eig: -0.002994046612886514, reward: 0.07706834054224616\n",
      "[6]: max_eig: -0.041960580566238956, reward: 0.07985262619070847\n",
      "[7]: max_eig: -1.3829297049119704, reward: 0.24755511801452773\n",
      "[8]: max_eig: -1.529827723719683, reward: 0.275846165225002\n",
      "[9]: max_eig: -1.4942726604381331, reward: 0.2688168493439073\n",
      "[10]: max_eig: -1.3764167581392424, reward: 0.24634723404286968\n",
      "[11]: max_eig: -1.3730170278994915, reward: 0.24571831239075484\n",
      "[12]: max_eig: -1.4198717870930178, reward: 0.25448175432681025\n",
      "[13]: max_eig: -2.0582320203159465, reward: 0.39231977581176886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling parameters:  70%|███████   | 7/10 [00:55<00:18,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]: max_eig: -3.3067351248347485, reward: 0.692413343171276\n",
      "[0]: max_eig: -0.2805071757824291, reward: 0.09901363302651202\n",
      "[1]: max_eig: -0.20637271808006605, reward: 0.09265212379323885\n",
      "[2]: max_eig: -0.6128400120184175, reward: 0.13256862504812034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling parameters:  80%|████████  | 8/10 [00:56<00:09,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]: max_eig: -3.549225856265859, reward: 0.7416262146300213\n",
      "[0]: max_eig: 1.417503267618468, reward: 0.020502770882714995\n",
      "[1]: max_eig: -0.0025270625928838384, reward: 0.07703552649235558\n",
      "[2]: max_eig: -0.0025507910454527446, reward: 0.07703719353080359\n",
      "[3]: max_eig: -0.002431319373127758, reward: 0.07702880040923589\n",
      "[4]: max_eig: -0.024600561152609213, reward: 0.07860086631001854\n",
      "[5]: max_eig: -0.04821003909004105, reward: 0.08030775130233202\n",
      "[6]: max_eig: -0.04780506606970562, reward: 0.08027818600683453\n",
      "[7]: max_eig: -0.004160558442574374, reward: 0.07715036582007465\n",
      "[8]: max_eig: -0.0023662876943378484, reward: 0.07702423216238156\n",
      "[9]: max_eig: -0.0026200286309514377, reward: 0.07704205799746361\n",
      "[10]: max_eig: -0.002423660834457003, reward: 0.077028262410727\n",
      "[11]: max_eig: -0.003708570242020224, reward: 0.07711857386887086\n",
      "[12]: max_eig: -0.0022665830225098564, reward: 0.07701722874880361\n",
      "[13]: max_eig: -0.002122954632048134, reward: 0.07700714110466082\n",
      "[14]: max_eig: -0.002214635289069144, reward: 0.07701358009259286\n",
      "[15]: max_eig: -0.002221695626219654, reward: 0.07701407598049831\n",
      "[16]: max_eig: 161.63907498905493, reward: 0.0010000020611536182\n",
      "[17]: max_eig: -0.005749845620537143, reward: 0.07726224988093225\n",
      "[18]: max_eig: 191.0309692796586, reward: 0.0010000020611536182\n",
      "[19]: max_eig: -0.0028351763933046874, reward: 0.07705717558570198\n",
      "[20]: max_eig: -0.002366215627729959, reward: 0.07702422710009538\n",
      "[21]: max_eig: -0.003793154804753092, reward: 0.07712452245232286\n",
      "[22]: max_eig: -1.3430241489915822, reward: 0.24021722299292395\n",
      "[23]: max_eig: -1.3418945578704742, reward: 0.2400117066203532\n",
      "[24]: max_eig: -1.336449611545293, reward: 0.239022759758447\n",
      "[25]: max_eig: -1.3344990485731412, reward: 0.2386691709955082\n",
      "[26]: max_eig: -1.330229224514447, reward: 0.23789642018084914\n",
      "[27]: max_eig: -1.3029012251281702, reward: 0.23299173035060597\n",
      "[28]: max_eig: -1.036520271546103, reward: 0.1889356866787747\n",
      "[29]: max_eig: -1.3350770519535349, reward: 0.23877391099248474\n",
      "[30]: max_eig: -1.3416743120413153, reward: 0.23997164948604074\n",
      "[31]: max_eig: -0.07543364692249714, reward: 0.08231846966225154\n",
      "[32]: max_eig: -0.02058071246101983, reward: 0.07831361780285233\n",
      "[33]: max_eig: -0.0815961284503119, reward: 0.08278003205218447\n",
      "[34]: max_eig: -0.30957551175098513, reward: 0.10161367487061074\n",
      "[35]: max_eig: -0.14923975920657565, reward: 0.08800536342178779\n",
      "[36]: max_eig: -1.1335088229688124, reward: 0.20418734114196088\n",
      "[37]: max_eig: 0.395248184601818, reward: 0.05338896277978202\n",
      "[38]: max_eig: 0.6901338429113726, reward: 0.04053869650120705\n",
      "[39]: max_eig: -0.07199956933502952, reward: 0.082062292809662\n",
      "[40]: max_eig: -1.1693743735064073, reward: 0.2100558980854601\n",
      "[41]: max_eig: -0.2377581314265227, reward: 0.0952987246317293\n",
      "[42]: max_eig: -1.3461311474795048, reward: 0.24078313100078652\n",
      "[43]: max_eig: -1.3629035690652298, reward: 0.24385385855459146\n",
      "[44]: max_eig: -2.217429995598004, reward: 0.4308238181838224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling parameters:  90%|█████████ | 9/10 [01:09<00:07,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45]: max_eig: -2.945400849173856, reward: 0.610545189860243\n",
      "[0]: max_eig: 21143.314474941577, reward: 0.0010000020611536182\n",
      "[1]: max_eig: 35990.39248110202, reward: 0.0010000020611536182\n",
      "[2]: max_eig: 30119.525588306155, reward: 0.0010000020611536182\n",
      "[3]: max_eig: 18481.155339424768, reward: 0.0010000020611536182\n",
      "[4]: max_eig: 13222.227469907215, reward: 0.0010000020611536182\n",
      "[5]: max_eig: 24815.9178398235, reward: 0.0010000020611536182\n",
      "[6]: max_eig: 4210.259715255856, reward: 0.0010000020611536182\n",
      "[7]: max_eig: 1420.7297689468624, reward: 0.0010000020611536182\n",
      "[8]: max_eig: -0.004253984916593236, reward: 0.07715693877177968\n",
      "[9]: max_eig: -0.004309461631842164, reward: 0.0771608420421107\n",
      "[10]: max_eig: -0.04309246969033371, reward: 0.07993488003317908\n",
      "[11]: max_eig: -1.9485145069668837, reward: 0.3665198319744743\n",
      "[12]: max_eig: -0.08461270625419225, reward: 0.08300683905498406\n",
      "[13]: max_eig: 60.05931950903243, reward: 0.0010000020611536182\n",
      "[14]: max_eig: 2.417289035452572, reward: 0.00826576762150166\n",
      "[15]: max_eig: -0.8889656290064054, reward: 0.16744505428990822\n",
      "[16]: max_eig: 4.420599932870435, reward: 0.0019862638100086333\n",
      "[17]: max_eig: 53.9047162414497, reward: 0.0010000020611536182\n",
      "[18]: max_eig: 319.6735409388027, reward: 0.0010000020611536182\n",
      "[19]: max_eig: 286.0164227559305, reward: 0.0010000020611536182\n",
      "[20]: max_eig: -2.2285021011976407, reward: 0.4335394000838456\n",
      "[21]: max_eig: -1.4723931634563237, reward: 0.26454833180542503\n",
      "[22]: max_eig: -1.0482311194357088, reward: 0.19072948284682006\n",
      "[23]: max_eig: -1.339551165331526, reward: 0.23958573912475867\n",
      "[24]: max_eig: -1.01498456127015, reward: 0.18567106181216209\n",
      "[25]: max_eig: -1.289678012072167, reward: 0.2306440838579758\n",
      "[26]: max_eig: -1.4107820830508122, reward: 0.2527655783371382\n",
      "[27]: max_eig: -0.8952586283716968, reward: 0.16831998557956857\n",
      "[28]: max_eig: -1.7951379165485501, reward: 0.33173512425539475\n",
      "[29]: max_eig: -2.3847305750365786, reward: 0.47221450953418187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling parameters: 100%|██████████| 10/10 [01:18<00:00,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]: max_eig: -2.6612128986980452, reward: 0.5412161622196827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output = sample_params(policy, kinetic_env, obs_mean, obs_var, N=10, max_steps=50, verbose=True, deterministic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the generated kinetic models or inspect the rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_states, final_rewards, final_max_eigs, steps_to_valid_solution = output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, compute IR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IR: 0.8 and average number of steps to valid solution: 21.875\n"
     ]
    }
   ],
   "source": [
    "ir = sum([1 for r in final_rewards if r > 0.5]) / len(final_rewards)\n",
    "\n",
    "print(f\"IR: {ir} and average number of steps to valid solution: {steps_to_valid_solution}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaexam22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
